{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/chocolatethunder/anaconda3/envs/ML/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputsz = 2 \n",
    "n_epoch = 2\n",
    "img_size = 299\n",
    "batch_size = 32\n",
    "train_dir = \"train/\"\n",
    "val_dir = \"val/\"\n",
    "n_images = 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting images to numpy arrays (takes a lot of memory so not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []\n",
    "valid_image_extensions = [\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"]\n",
    "valid_image_extensions = [item.lower() for item in valid_image_extensions]\n",
    "    \n",
    "for file in os.listdir(imageDir):\n",
    "    extension = os.path.splitext(file)[1]\n",
    "    if extension.lower() not in valid_image_extensions:\n",
    "        continue\n",
    "    image_path_list.append(os.path.join(imageDir, file))\n",
    "\n",
    "img_num = len(image_path_list)\n",
    "    \n",
    "x = np.zeros((10000,img_sz,img_sz,3))\n",
    "y = np.zeros((img_num))\n",
    "\n",
    "for ii in range(10000):\n",
    "    im = cv2.imread(image_path_list[ii])\n",
    "    resized_image = cv2.resize(im, (img_sz, img_sz))\n",
    "    x[ii,:,:,:] = resized_image\n",
    "    \n",
    "    if image_path_list[0].find(\"dog\") >=0:\n",
    "        y[ii] = 1\n",
    "    else:\n",
    "        y[ii] =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating generator to get images from directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocess_input scales and centers the images sample wise\n",
    "# this function also adds random noise to the data by rotations, shifts, zooms and shears\n",
    "train_datagen =  image.ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "\n",
    "\n",
    "#create generators for data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(img_size, img_size),\n",
    "batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_datagen = image.ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "\n",
    "\n",
    "#val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model with a base  from inceptionv3 weights from imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chocolatethunder/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#include_top = False means that we do not take the final layers from InceptionV3\n",
    "Iv3 = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a final layers to the model, do Global Average Pooling, Dense and FC\n",
    "x =Iv3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "y = Dense(outputsz, activation='softmax')(x)\n",
    "#create model\n",
    "model = Model(input=Iv3.input, output=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 18242s 29s/step - loss: 0.1772\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 10693s 17s/step - loss: 0.1161\n"
     ]
    }
   ],
   "source": [
    "#at first we only train the added layers so we freeze all the layers below\n",
    "for layer in Iv3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#use categorical loss entropy because it is equivalent to log loss which is the metric of the competition\n",
    "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy')\n",
    "\n",
    "#train the model\n",
    "transfer_learn = model.fit_generator(generator = train_generator, \n",
    "                                     steps_per_epoch = n_images/batch_size,\n",
    "                                     epochs = n_epoch,\n",
    "                                     validation_data = val_generator,\n",
    "                                     validation_steps = 156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once the last layers have been trained we go back and fine tune some of the levels of the model. We use a low training rate since we assume that the features are good and we do not want them to change very much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 67309s 108s/step - loss: 0.0752\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 69730s 112s/step - loss: 0.0471\n"
     ]
    }
   ],
   "source": [
    "# unfreeze the last two blocks so we can train them\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "   \n",
    "#finetune with a smaller learning rate, we want to make sure things change quite slowly \n",
    "model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy')\n",
    "\n",
    "#train the model\n",
    "transfer_learn = model.fit_generator(generator = train_generator, \n",
    "                                     steps_per_epoch = n_images/batch_size,\n",
    "                                     epochs = n_epoch,\n",
    "                                     validation_data = val_generator,\n",
    "                                     validation_steps = 156)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the remaning validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we see it does not overfit than we train on the remaining validation images for one \n",
    "#epoch\n",
    "transfer_learn = model.fit_generator(generator = val_generator, \n",
    "                                     steps_per_epoch = 5000/batch_size,\n",
    "                                     epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transfer_learning1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#predict all of the test images\n",
    "#for some reason using the fit_generator even with shuffle = false, shuffled the images so instead\n",
    "#I had to take them out image by image to be predicted, this is inefficient but it didn't work if I did\n",
    "# it by a batch at a time either\n",
    "predict = np.zeros((12500,2))\n",
    "for ii in range(12500):\n",
    "    img_dir = \"test/T/{0}.jpg\".format(ii+1)\n",
    "    im = cv2.imread(img_dir)\n",
    "    resized_image = cv2.resize(im, (img_size, img_size))\n",
    "    resized_image = resized_image/127.5\n",
    "    resized_image -= 1.\n",
    "    batch_img = np.zeros((1,299,299,3))\n",
    "    batch_img[0,:,:,:] = resized_image\n",
    "    predict[ii,:] = model.predict(batch_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only predictions for dogs\n",
    "dog = predict[:,1]\n",
    "#clip values\n",
    "dog_clip = np.clip(dog, a_min = 0.005, a_max = 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to create csv files from the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"Id\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "write_preds(dog, \"dog.csv\")\n",
    "write_preds(dog_clip, \"dog_clip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
